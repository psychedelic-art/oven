# Module: AI

> **Package**: `packages/module-ai/`
> **Name**: `@oven/module-ai`
> **Dependencies**: `module-registry`, `module-roles`
> **Status**: Planned

---

## 1. Overview

Module AI is the **unified AI services layer** for the OVEN platform. It provides a provider-agnostic abstraction over language models, embedding engines, image generators, video generators, speech services, and vector databases — all exposed as a curated **tool catalog** with Zod-based schemas that any agent workflow, chat session, or module can consume.

The design is built on top of the **Vercel AI SDK** (`ai` + `@ai-sdk/*` provider packages) as the runtime backbone. The AI SDK's provider system, tool definitions, structured output, streaming, and React hooks provide the foundation. Module AI wraps this foundation with OVEN conventions: JSONB configuration stored in Postgres, CRUD management through React Admin, registry-based discovery, permission enforcement, and usage tracking.

### Why a Separate Module?

Without `module-ai`, every agent or workflow that needs to call an LLM, generate an image, embed a document, or query a vector database would need to implement its own integration. Module AI centralizes these concerns:

- **Provider management** — Configure API keys, select models, set defaults, and switch providers from the dashboard without code changes
- **Tool catalog** — Every AI capability is registered as a tool with a Zod schema, making it discoverable by agents via the Module Registry and invokable through the Tool Wrapper
- **Usage tracking** — All AI API calls are metered, logged, and attributable to the user/agent/session that triggered them
- **Cost control** — Rate limits, token budgets, and spending caps are enforced centrally
- **Schema-first** — Every tool declares its input/output schema so workflows can validate parameters at design time, and the visual editor can render appropriate input forms

### Architectural Role

```
module-chat  ──→  module-agent-core  ──→  module-workflow-agents
     │                    │                         │
     │  uses @ai-sdk/react hooks                    │
     │                    │                         │
     └────────────────────┼─────────────────────────┘
                          │ all discover & invoke tools from
                          ▼
                    ┌─────────────┐
                    │  module-ai  │
                    │             │
                    │  Provider   │  ← @ai-sdk/openai, @ai-sdk/google,
                    │  Registry   │    @ai-sdk/anthropic, @ai-sdk/mistral …
                    │             │
                    │  Tool       │  ← generateText, streamText, embed,
                    │  Catalog    │    generateImage, transcribe, tts …
                    │             │
                    │  Vector DB  │  ← Pinecone, pgvector, Qdrant,
                    │  Adapters   │    ChromaDB, Weaviate, Upstash …
                    │             │
                    │  Usage      │  ← token metering, cost tracking,
                    │  Tracking   │    rate limiting, audit log
                    └─────────────┘
```

### Design Goals

- **Provider-agnostic** — Built on the Vercel AI SDK's `customProvider()` pattern. All LLM, embedding, image, speech, and transcription models are accessed through a unified provider registry. Switching from OpenAI to Anthropic or Google is a configuration change, not a code change
- **Schema-driven tools** — Every AI capability is a `tool()` definition with a Zod `inputSchema` and `outputSchema`. Agent workflows can bind to these tools and validate inputs at design time
- **Composable with workflows** — Module AI tools are registered in the Module Registry and auto-discovered by `module-agent-core`'s Tool Wrapper. Agent workflows use them as `agent.toolExecutor` targets
- **React hooks for the frontend** — The Chat UI and other frontend modules use `@ai-sdk/react` hooks (`useChat`, `useCompletion`, `useObject`) for streaming interactions, powered by Module AI's server-side endpoints
- **Multi-modal** — Supports text, images (URL, base64, binary), audio, video, PDF, and file inputs/outputs across all applicable providers
- **Vector-native** — First-class integration with vector databases for RAG (Retrieval-Augmented Generation) workflows: embed, store, search, retrieve

---

## 2. Core Concepts

### 2.1 Provider Registry

Module AI maintains a **provider registry** — a database-backed configuration layer that maps provider slugs to Vercel AI SDK provider instances. Each provider record stores:

- **Provider slug** — e.g., `openai`, `anthropic`, `google`, `mistral`, `groq`, `deepseek`
- **API key** — Encrypted, stored securely, never exposed to the frontend
- **Default models** — Which model to use when a caller doesn't specify (e.g., `gpt-4o` for language, `text-embedding-3-small` for embeddings)
- **Enabled status** — Providers can be disabled without deleting their configuration
- **Rate limits** — Per-provider request and token rate limits
- **Custom provider alias** — Using `customProvider()` from the AI SDK, administrators can create aliases like `fast` → `gpt-4o-mini`, `smart` → `claude-sonnet-4-20250514`

At runtime, Module AI constructs an AI SDK `customProvider` from the database configuration. This provider is the single entry point for all downstream AI calls — agent workflows, chat sessions, and direct API callers all go through it.

**Supported Provider Packages**:

| Package | Provider | Capabilities |
|---------|----------|-------------|
| `@ai-sdk/openai` | OpenAI | Language, embeddings, image (DALL-E), TTS, transcription (Whisper) |
| `@ai-sdk/anthropic` | Anthropic | Language, vision |
| `@ai-sdk/google` | Google Generative AI | Language, embeddings, image (Imagen), vision, audio |
| `@ai-sdk/mistral` | Mistral | Language, embeddings |
| `@ai-sdk/groq` | Groq | Language (fast inference) |
| `@ai-sdk/azure` | Azure OpenAI | Language, embeddings, image |
| `@ai-sdk/amazon-bedrock` | AWS Bedrock | Language, embeddings |
| `@ai-sdk/cohere` | Cohere | Language, embeddings, reranking |
| `@ai-sdk/deepseek` | DeepSeek | Language |
| `@ai-sdk/xai` | xAI (Grok) | Language |
| `@ai-sdk/replicate` | Replicate | Image, video (open-source models) |
| `@ai-sdk/fal` | fal.ai | Image (fast inference), video |

### 2.2 Tool Catalog

The tool catalog is the heart of Module AI. Every AI capability is wrapped as a **tool** following the AI SDK `tool()` pattern — a function with a Zod `inputSchema`, an optional `outputSchema`, a description, and an `execute` function.

Tools are organized into **categories**:

**Language Model Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.generateText` | Non-streaming text generation | `model`, `prompt`, `system?`, `temperature?`, `maxTokens?`, `tools?` |
| `ai.streamText` | Streaming text generation (SSE) | Same as generateText, returns stream |
| `ai.generateObject` | Structured output against a Zod schema | `model`, `prompt`, `schema` (JSON Schema), `system?` |
| `ai.streamObject` | Streaming structured output | Same as generateObject, returns partial stream |
| `ai.generateChoice` | Constrained classification / selection | `model`, `prompt`, `options` (string[]) |

**Embedding Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.embed` | Embed a single text value | `model?`, `value` (string) |
| `ai.embedMany` | Batch embed multiple values | `model?`, `values` (string[]) |
| `ai.cosineSimilarity` | Compute similarity between two vectors | `vectorA` (number[]), `vectorB` (number[]) |

**Image Generation Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.generateImage` | Generate an image from text | `model?`, `prompt`, `size?`, `aspectRatio?`, `n?`, `style?`, `quality?` |
| `ai.editImage` | Edit/inpaint an existing image | `model?`, `prompt`, `image` (base64/URL), `mask?` |
| `ai.describeImage` | Describe image content (vision) | `model?`, `image` (base64/URL), `prompt?` |

**Video Generation Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.generateVideo` | Generate video from text/image | `provider` (runway/replicate/fal), `prompt`, `image?`, `duration?`, `aspectRatio?` |
| `ai.getVideoStatus` | Poll async video generation job | `jobId`, `provider` |

**Speech & Audio Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.textToSpeech` | Convert text to audio | `model?`, `text`, `voice?`, `speed?`, `format?` |
| `ai.transcribe` | Convert audio to text | `model?`, `audio` (base64/URL), `language?` |

**Vector Database Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.vectorStore.upsert` | Store vectors with metadata | `store`, `vectors` ({ id, values, metadata }[]) |
| `ai.vectorStore.query` | Semantic similarity search | `store`, `vector` (number[]) or `text` (string), `topK?`, `filter?` |
| `ai.vectorStore.delete` | Remove vectors by ID or filter | `store`, `ids?`, `filter?` |
| `ai.vectorStore.fetch` | Retrieve vectors by ID | `store`, `ids` (string[]) |

**RAG (Retrieval-Augmented Generation) Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.rag.ingest` | Chunk, embed, and store a document | `store`, `content` (string/URL), `chunkStrategy?`, `metadata?` |
| `ai.rag.retrieve` | Search + rerank + return context | `store`, `query` (string), `topK?`, `rerank?`, `filter?` |
| `ai.rag.ask` | End-to-end RAG: retrieve + generate answer | `store`, `question`, `model?`, `system?` |

**Document & Content Tools**

| Tool | Description | Key Input Schema Fields |
|------|-------------|------------------------|
| `ai.parseDocument` | Extract text/structure from PDF, DOCX, etc. | `file` (base64/URL), `mediaType`, `pages?` |
| `ai.translate` | Translate text between languages | `text`, `from?`, `to`, `model?` |
| `ai.moderate` | Content moderation / safety check | `text?`, `image?`, `model?` |
| `ai.summarize` | Summarize long text | `text`, `maxLength?`, `style?`, `model?` |

### 2.3 Tool Schema Contract

Every tool in the catalog follows this schema contract, enabling agent workflows to bind to them at design time:

```
ToolDefinition {
  name: string               — unique identifier (e.g., "ai.generateImage")
  category: string           — grouping (language, embedding, image, video, speech, vector, rag, document)
  description: string        — what this tool does (for LLM tool selection)
  inputSchema: JSONSchema    — Zod-derived JSON Schema for input validation
  outputSchema: JSONSchema   — Zod-derived JSON Schema for output typing
  provider: string | null    — which provider this tool requires (null = any)
  isAsync: boolean           — whether this tool returns immediately or requires polling
  requiredCapability: string — provider capability needed (e.g., "imageGeneration", "embedding")
  costEstimate: string       — rough cost category (free, low, medium, high)
}
```

This schema is registered in the Module Registry's `chat` block so agents and workflows can discover tools and understand their parameters without hardcoding.

### 2.4 Vector Database Adapters

Module AI provides a unified vector database interface with pluggable adapters. Each adapter implements a common contract (upsert, query, delete, fetch) and is configured per-store through the dashboard.

**Supported Adapters**:

| Adapter | Backend | Key Features | Use Case |
|---------|---------|-------------|----------|
| `pgvector` | PostgreSQL + pgvector extension | SQL-based, co-located with app data, HNSW/IVFFlat indexes | Default — no extra infrastructure |
| `pinecone` | Pinecone (managed) | Serverless, namespaces, metadata filtering, hybrid search | Production scale, managed service |
| `qdrant` | Qdrant | Collections, payload filtering, high performance | Self-hosted or cloud, advanced filtering |
| `chromadb` | ChromaDB | Simple API, embedding functions, collections | Local development, prototyping |
| `weaviate` | Weaviate | GraphQL API, vectorizer modules, hybrid search | Schema-rich use cases |
| `upstash-vector` | Upstash Vector | Serverless, Redis-based, edge-compatible | Edge deployments, Vercel |
| `supabase-vector` | Supabase (pgvector) | Supabase auth + storage + vector in one | Supabase-native apps |

Each vector store instance is a database record with:
- **Slug** — identifier (e.g., `knowledge-base`, `product-catalog`)
- **Adapter** — which backend (`pgvector`, `pinecone`, etc.)
- **Connection config** — adapter-specific connection parameters (encrypted)
- **Embedding model** — which embedding model to use for automatic embedding
- **Dimensions** — vector dimensionality (must match embedding model)
- **Distance metric** — `cosine`, `euclidean`, or `dotProduct`
- **Metadata schema** — optional JSON Schema defining what metadata fields are expected

### 2.5 AI SDK React Integration

Module AI exposes server-side endpoints that are compatible with the `@ai-sdk/react` hooks. The Chat module and other frontend modules use these hooks directly:

**`useChat`** — Full chat interface with streaming, tool invocations, and multi-modal support. Connects to Module AI's streaming endpoint via `DefaultChatTransport`.

**`useCompletion`** — Single-turn text completion with streaming. Used for inline autocomplete, search suggestions, and content generation fields.

**`useObject`** — Streaming structured objects validated against Zod schemas. Used for form auto-fill, data extraction panels, and structured AI responses.

These hooks are consumed by `module-chat` for its conversational UI, but any module's frontend can import them for AI-powered features (e.g., a form module could use `useObject` for AI-assisted form filling).

### 2.6 Middleware Layer

Module AI applies a middleware stack to all AI calls using the AI SDK's `wrapLanguageModel` pattern:

- **Usage tracking middleware** — Records input/output tokens, model used, latency, and cost for every call
- **Rate limiting middleware** — Enforces per-user, per-provider, and global rate limits via `transformParams`
- **Audit logging middleware** — Logs who called what, when, with which parameters (respecting data sensitivity settings)
- **Guardrail middleware** — Optional content moderation on inputs and outputs via `wrapGenerate`/`wrapStream`
- **Default settings middleware** — Applies provider-specific defaults (e.g., reasoning effort) via `defaultSettingsMiddleware`
- **Caching middleware** — Optional response caching for deterministic queries (same prompt + seed = cached result)

---

## 3. Database Schema

### Tables

**`ai_providers`** — Configured AI providers
- `id` (serial, PK)
- `name` (varchar) — human-readable name (e.g., "OpenAI Production")
- `slug` (varchar, unique) — identifier
- `providerType` (varchar) — the AI SDK provider package (`openai`, `anthropic`, `google`, `mistral`, `groq`, etc.)
- `apiKey` (text, encrypted) — API key for this provider
- `baseUrl` (varchar, nullable) — custom API base URL (for self-hosted or proxy endpoints)
- `defaultLanguageModel` (varchar, nullable) — default language model ID
- `defaultEmbeddingModel` (varchar, nullable) — default embedding model ID
- `defaultImageModel` (varchar, nullable) — default image model ID
- `config` (JSONB) — additional provider-specific configuration
- `rateLimits` (JSONB) — rate limit settings (requestsPerMinute, tokensPerMinute)
- `enabled` (boolean, default true)
- `createdAt`, `updatedAt` (timestamps)

**`ai_model_aliases`** — Custom model aliases (e.g., "fast" → "gpt-4o-mini")
- `id` (serial, PK)
- `alias` (varchar, unique) — the alias name
- `providerId` (integer, FK → ai_providers)
- `modelId` (varchar) — the actual model ID at the provider
- `modelType` (varchar) — language, embedding, image, speech, transcription
- `defaultSettings` (JSONB, nullable) — default parameters applied when this alias is used
- `createdAt`, `updatedAt` (timestamps)

**`ai_tool_configs`** — Per-tool configuration overrides
- `id` (serial, PK)
- `toolName` (varchar) — tool identifier from the catalog (e.g., `ai.generateImage`)
- `providerId` (integer, nullable, FK → ai_providers) — preferred provider for this tool
- `modelId` (varchar, nullable) — preferred model
- `defaultParams` (JSONB) — default parameters merged into every invocation
- `enabled` (boolean, default true)
- `createdAt`, `updatedAt` (timestamps)

**`ai_vector_stores`** — Vector database store configurations
- `id` (serial, PK)
- `name` (varchar) — human-readable name
- `slug` (varchar, unique) — identifier used in tool calls
- `adapter` (varchar) — pgvector, pinecone, qdrant, chromadb, weaviate, upstash-vector, supabase-vector
- `connectionConfig` (JSONB, encrypted) — adapter-specific connection parameters
- `embeddingProviderId` (integer, nullable, FK → ai_providers) — which provider for auto-embedding
- `embeddingModel` (varchar, nullable) — embedding model ID
- `dimensions` (integer) — vector dimensionality
- `distanceMetric` (varchar, default 'cosine') — cosine, euclidean, dotProduct
- `metadataSchema` (JSONB, nullable) — JSON Schema for expected metadata fields
- `chunkConfig` (JSONB, nullable) — default chunking strategy for ingestion (chunkSize, overlap, splitter)
- `enabled` (boolean, default true)
- `createdAt`, `updatedAt` (timestamps)

**`ai_usage_logs`** — Usage tracking for all AI API calls
- `id` (serial, PK)
- `userId` (integer, nullable) — who triggered this call
- `agentId` (integer, nullable) — which agent (if agent-initiated)
- `sessionId` (integer, nullable) — which session
- `toolName` (varchar) — which tool was called
- `providerId` (integer, FK → ai_providers)
- `modelId` (varchar) — specific model used
- `inputTokens` (integer, nullable)
- `outputTokens` (integer, nullable)
- `totalTokens` (integer, nullable)
- `latencyMs` (integer)
- `estimatedCost` (decimal, nullable) — cost in USD based on model pricing
- `status` (varchar) — success, error, rate_limited
- `error` (text, nullable)
- `metadata` (JSONB) — additional context (image size, audio duration, etc.)
- `createdAt` (timestamp)

**`ai_usage_budgets`** — Spending caps and token budgets
- `id` (serial, PK)
- `scope` (varchar) — global, provider, user, agent
- `scopeId` (integer, nullable) — FK to the scoped entity
- `period` (varchar) — daily, weekly, monthly
- `tokenLimit` (integer, nullable) — max tokens per period
- `costLimit` (decimal, nullable) — max USD per period
- `currentUsage` (JSONB) — rolling usage counters
- `alertThreshold` (decimal, default 0.8) — emit warning event at this % of limit
- `enabled` (boolean, default true)
- `createdAt`, `updatedAt` (timestamps)

---

## 4. API Endpoints

### Provider Management

| Method | Route | Purpose |
|--------|-------|---------|
| GET | `/api/ai/providers` | List configured providers |
| POST | `/api/ai/providers` | Add a new provider configuration |
| GET | `/api/ai/providers/[id]` | Get provider details (API key masked) |
| PUT | `/api/ai/providers/[id]` | Update provider configuration |
| DELETE | `/api/ai/providers/[id]` | Remove a provider |
| POST | `/api/ai/providers/[id]/test` | Test provider connectivity and API key |
| GET | `/api/ai/providers/[id]/models` | List available models for a provider |

### Model Aliases

| Method | Route | Purpose |
|--------|-------|---------|
| GET | `/api/ai/aliases` | List model aliases |
| POST | `/api/ai/aliases` | Create a model alias |
| PUT | `/api/ai/aliases/[id]` | Update an alias |
| DELETE | `/api/ai/aliases/[id]` | Delete an alias |

### Tool Catalog

| Method | Route | Purpose |
|--------|-------|---------|
| GET | `/api/ai/tools` | List all available AI tools with schemas |
| GET | `/api/ai/tools/[name]` | Get a specific tool's schema and configuration |
| PUT | `/api/ai/tools/[name]/config` | Override default configuration for a tool |
| POST | `/api/ai/tools/[name]/invoke` | **Invoke a tool directly** (authenticated, metered) |

### Language Model Endpoints

| Method | Route | Purpose |
|--------|-------|---------|
| POST | `/api/ai/generate` | Generate text (non-streaming) |
| POST | `/api/ai/stream` | Stream text generation (SSE) — compatible with `useChat` |
| POST | `/api/ai/generate-object` | Generate structured output against a schema |
| POST | `/api/ai/stream-object` | Stream structured output (SSE) — compatible with `useObject` |

### Embedding Endpoints

| Method | Route | Purpose |
|--------|-------|---------|
| POST | `/api/ai/embed` | Embed a single value |
| POST | `/api/ai/embed-many` | Batch embed multiple values |
| POST | `/api/ai/similarity` | Compute cosine similarity between vectors |

### Image Endpoints

| Method | Route | Purpose |
|--------|-------|---------|
| POST | `/api/ai/images/generate` | Generate image(s) from text prompt |
| POST | `/api/ai/images/edit` | Edit/inpaint an image |
| POST | `/api/ai/images/describe` | Describe image content (vision) |

### Video Endpoints

| Method | Route | Purpose |
|--------|-------|---------|
| POST | `/api/ai/videos/generate` | Submit async video generation job |
| GET | `/api/ai/videos/[jobId]` | Poll video generation status |

### Speech & Audio Endpoints

| Method | Route | Purpose |
|--------|-------|---------|
| POST | `/api/ai/speech/synthesize` | Text-to-speech |
| POST | `/api/ai/speech/transcribe` | Speech-to-text |

### Vector Store Endpoints

| Method | Route | Purpose |
|--------|-------|---------|
| GET | `/api/ai/vector-stores` | List configured vector stores |
| POST | `/api/ai/vector-stores` | Create a vector store configuration |
| GET | `/api/ai/vector-stores/[id]` | Get vector store details |
| PUT | `/api/ai/vector-stores/[id]` | Update vector store configuration |
| DELETE | `/api/ai/vector-stores/[id]` | Remove a vector store |
| POST | `/api/ai/vector-stores/[slug]/upsert` | Upsert vectors |
| POST | `/api/ai/vector-stores/[slug]/query` | Semantic search |
| POST | `/api/ai/vector-stores/[slug]/delete` | Delete vectors |
| POST | `/api/ai/vector-stores/[slug]/fetch` | Fetch vectors by ID |

### RAG Endpoints

| Method | Route | Purpose |
|--------|-------|---------|
| POST | `/api/ai/rag/ingest` | Chunk, embed, and store a document |
| POST | `/api/ai/rag/retrieve` | Search + rerank + return context |
| POST | `/api/ai/rag/ask` | End-to-end RAG query |

### Usage & Budgets

| Method | Route | Purpose |
|--------|-------|---------|
| GET | `/api/ai/usage` | Query usage logs (filterable by user, agent, provider, date range) |
| GET | `/api/ai/usage/summary` | Aggregated usage statistics |
| GET | `/api/ai/budgets` | List spending budgets |
| POST | `/api/ai/budgets` | Create a budget |
| PUT | `/api/ai/budgets/[id]` | Update a budget |
| DELETE | `/api/ai/budgets/[id]` | Delete a budget |

---

## 5. Tool Invocation Flow

When an agent workflow calls an AI tool (e.g., `ai.generateImage`):

```
Agent Workflow (module-workflow-agents)
  ↓ agent.toolExecutor node resolves tool "ai.generateImage"
  ↓
Tool Wrapper (module-agent-core)
  ↓ matches tool name to module-ai's registered tool catalog
  ↓
Module AI — POST /api/ai/tools/ai.generateImage/invoke
  ↓
1. Validate input against tool's Zod inputSchema
2. Resolve provider: tool config → model alias → provider registry → default
3. Apply middleware stack (rate limiting, usage tracking, guardrails)
4. Call AI SDK function (e.g., generateImage({ model, prompt, ... }))
5. Record usage in ai_usage_logs
6. Check budget limits, emit warning events if approaching threshold
7. Return result conforming to tool's outputSchema
  ↓
Tool result flows back through agent workflow state
```

### Direct Frontend Usage

Frontend modules can also call AI tools directly:

```
React Component (e.g., module-chat frontend)
  ↓ uses @ai-sdk/react useChat() hook
  ↓ configured with DefaultChatTransport({ api: '/api/ai/stream' })
  ↓
Module AI — POST /api/ai/stream
  ↓ Same middleware stack, same usage tracking
  ↓ Returns SSE stream compatible with useChat
  ↓
React hook updates UI with streaming tokens
```

---

## 6. AI SDK Integration Architecture

### Server-Side (API Routes)

Module AI's API endpoints use the AI SDK Core functions internally:

- `/api/ai/generate` → calls `generateText()` from `ai`
- `/api/ai/stream` → calls `streamText()` from `ai`, returns `result.toUIMessageStreamResponse()`
- `/api/ai/generate-object` → calls `generateText()` with `Output.object({ schema })` from `ai`
- `/api/ai/embed` → calls `embed()` from `ai`
- `/api/ai/images/generate` → calls `generateImage()` from `ai`

The provider is resolved from the database configuration and constructed at runtime using `customProvider()`.

### Client-Side (React Hooks)

The `@ai-sdk/react` hooks connect to Module AI's streaming endpoints:

**Chat sessions** use `useChat`:
- Transport: `DefaultChatTransport({ api: '/api/ai/stream', headers: authHeaders })`
- Features: streaming, tool call rendering, multi-modal input (images, files), message history
- Status states: `submitted` → `streaming` → `ready`

**Structured output** uses `useObject`:
- Endpoint: `/api/ai/stream-object`
- Schema validation: Zod schema defined on both client and server
- Progressive filling: `object` property is deeply partial during streaming

**Completions** use `useCompletion`:
- Endpoint: `/api/ai/generate` or custom
- Use case: inline suggestions, search, autocomplete

### Agent Loop Integration

Module AI's tools participate in the AI SDK's agent loop pattern:

- **`stopWhen`** — Agent workflows configure `maxToolIterations` which maps to `stepCountIs(n)`
- **`prepareStep`** — Workflows can dynamically switch models per step via the provider registry
- **`toolChoice`** — Configurable per LLM node in the workflow: `auto`, `none`, `required`, or specific tool
- **`needsApproval`** — Maps to the `agent.humanReview` node pattern for high-stakes tool calls

---

## 7. Dashboard UI

### Resources (React Admin CRUD)

- **AI Providers** — List, create, edit providers with connectivity testing
- **Model Aliases** — Manage custom model aliases
- **Tool Catalog** — Browse all available AI tools, view schemas, configure defaults
- **Vector Stores** — List, create, edit vector store configurations
- **Usage Logs** — Searchable, filterable usage log with cost breakdown
- **Budgets** — Manage spending caps and token limits

### AI Playground

A **playground page** (`/ai/playground`) for testing AI tools directly:

- **Text generation** — Send prompts to any configured model, see streaming response
- **Image generation** — Generate images with parameter controls (size, style, quality)
- **Embedding explorer** — Embed text, visualize similarity, test vector store queries
- **Object generation** — Define a Zod schema in the UI, generate structured output
- **Speech** — TTS and transcription testing with audio playback

### Usage Dashboard

A **usage dashboard** (`/ai/usage`) showing:

- Token consumption over time (charts)
- Cost breakdown by provider, model, user, and agent
- Budget utilization gauges
- Top consumers (users and agents)
- Rate limit hit counts

### Menu Section

```
──── AI Services ────
Providers
Model Aliases
Tools
Vector Stores
Playground
Usage & Budgets
```

---

## 8. Events

| Event | Payload |
|-------|---------|
| `ai.provider.created` | id, slug, providerType |
| `ai.provider.updated` | id, slug |
| `ai.provider.deleted` | id, slug |
| `ai.provider.test.passed` | id, slug |
| `ai.provider.test.failed` | id, slug, error |
| `ai.alias.created` | id, alias, providerId, modelId |
| `ai.alias.deleted` | id, alias |
| `ai.tool.invoked` | toolName, providerId, modelId, userId, agentId, status |
| `ai.tool.failed` | toolName, providerId, error |
| `ai.vectorStore.created` | id, slug, adapter |
| `ai.vectorStore.updated` | id, slug |
| `ai.vectorStore.deleted` | id, slug |
| `ai.vectorStore.ingested` | storeSlug, documentCount, chunkCount |
| `ai.usage.budgetWarning` | budgetId, scope, currentUsage, limit, threshold |
| `ai.usage.budgetExceeded` | budgetId, scope, currentUsage, limit |
| `ai.usage.rateLimited` | userId, providerId, toolName |

---

## 9. Integration Points

| Module | Integration |
|--------|-------------|
| **module-agent-core** | Agents discover AI tools through the Module Registry. The Tool Wrapper routes `ai.*` tool calls to Module AI's invoke endpoint. Agent LLM configurations reference Module AI's provider registry for model resolution. |
| **module-workflow-agents** | Agent workflow `agent.llm` and `agent.toolExecutor` nodes use Module AI's generate/stream endpoints. Memory nodes use embedding + vector store tools. Tool-calling loops use Module AI tools as targets. |
| **module-chat** | Chat's frontend uses `@ai-sdk/react` hooks (`useChat`) connected to Module AI's streaming endpoint. Chat's backing agent uses Module AI tools for all LLM calls, tool executions, and RAG queries. |
| **module-registry** | Module AI registers its tool catalog in the Module Registry's `chat` block, enabling automatic discovery by agents and workflows. |
| **module-roles** | All AI tool invocations are subject to the calling user's permissions. Rate limits and budgets can be scoped to roles. |
| **module-workflows** | Standard (non-agent) workflows can invoke AI tools as workflow nodes — e.g., a form submission workflow that auto-summarizes content or generates embeddings. |
| **module-forms** | Forms can use `useObject` for AI-assisted field filling and `useCompletion` for inline suggestions. |
| **module-scoring-engine** | Scoring can use AI tools for automated essay evaluation, rubric application, and feedback generation. |
| **module-dashboards** | Dashboards can use AI tools for natural language queries against data, auto-generated insights, and data visualization suggestions. |

---

## 10. ModuleDefinition Self-Description

Module AI registers itself with a comprehensive `chat` block so agents can discover all AI capabilities:

- **description**: "Provides unified access to AI services: language models, embeddings, image generation, video generation, speech synthesis, transcription, vector databases, and RAG. All services are provider-agnostic and exposed as schema-defined tools."
- **capabilities**: "generate text", "stream text", "generate structured objects", "embed text", "generate images", "generate videos", "text-to-speech", "speech-to-text", "vector store operations", "RAG ingestion and retrieval", "content moderation", "document parsing", "translation", "summarization"
- **actionSchemas**: Full tool catalog with Zod-derived JSON Schemas for every tool (see Section 2.2)

---

## 11. Non-Functional Requirements

- **Streaming** — All generation endpoints support Server-Sent Events (SSE) for token-level streaming. Streaming responses are compatible with `@ai-sdk/react` hooks
- **Provider failover** — When a primary provider fails, the system can fall back to a configured secondary provider (via `fallbackProvider` in the AI SDK's `customProvider`)
- **Encryption** — API keys and vector store connection strings are encrypted at rest. They are never exposed through GET endpoints or the frontend
- **Rate limiting** — Enforced at three levels: per-user, per-provider, and global. Rate limit configuration is stored in `ai_providers` and enforced by middleware
- **Token budgets** — Configurable spending caps per period (daily/weekly/monthly) at global, provider, user, or agent scope. Approaching limits trigger warning events; exceeding limits blocks requests
- **Usage metering** — Every AI call is logged with tokens, latency, cost, and attribution. Usage data is queryable through the API and visualizable on the dashboard
- **Async job support** — Video generation and other long-running tasks use an async pattern: submit job → poll for status → retrieve result. The API returns a `jobId` immediately
- **Idempotency** — Tool invocations with the same idempotency key return cached results
- **Timeout safety** — All external API calls have configurable timeouts. The AI SDK's `timeout` parameter (`totalMs`, `stepMs`) is honored
- **Multi-tenancy ready** — Provider configurations and budgets can be scoped to tenants when multi-tenancy is enabled
- **Backward compatibility** — Adding new tools or providers does not require changes to existing agent definitions or workflows. New tools appear automatically in the catalog
